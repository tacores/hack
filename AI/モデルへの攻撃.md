# モデルへの攻撃

https://tryhackme.com/room/idadversarialattacks

## ニューラルネットワークを欺く敵対的サンプルを生成

PGDが最も複雑で、防御回避の効果が高い  
`FGSM < BIM < PGD`

https://cleverhans.io/ ライブラリを使用

```python
from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method
from cleverhans.tf2.attacks.basic_iterative_method import basic_iterative_method
from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent
import random

# Select samples
x_sample = x_test[:100]
y_sample = y_test[:100]

# Randomly choose an attack
attack_type = random.choice(["FGSM", "BIM", "PGD"])
print("Generating adversarial examples...")

# Generate adversarial examples
if attack_type == "FGSM":
    x_adv = fast_gradient_method(model_fn=model, x=x_sample, eps=0.1, norm=np.inf)
elif attack_type == "BIM":
    x_adv = basic_iterative_method(model_fn=model, x=x_sample, eps=0.1, eps_iter=0.01, nb_iter=10, norm=np.inf)
elif attack_type == "PGD":
    x_adv = projected_gradient_descent(model_fn=model, x=x_sample, eps=0.1, eps_iter=0.01, nb_iter=20, norm=np.inf)
```

## 防御

https://tryhackme.com/room/defadversarialattacks

### 基本の防御（対ホワイトボックス攻撃）

- 敵対的トレーニング
- 勾配の非表示
- 特徴圧縮（色深度の変更、ノイズ除去）

### 高度な防御（対ブラックボックス攻撃）

- NULLラベル付け
- MagNet
1. 検出器：入力データが不自然であるかどうか確認する
2. 改質器：オートエンコーダーで修復する
- 圧縮とフィルターの使用  
主成分分析、ローパスフィルタ、JPEG圧縮、ソフト閾値設定

